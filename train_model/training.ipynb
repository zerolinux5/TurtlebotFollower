{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2275b3b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d961650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d8344",
   "metadata": {},
   "source": [
    "### Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06391ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/GTL/jmagana/gte/ml/TurtlebotFollower/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dfe6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        data_dir = Path(data_dir)\n",
    "        self.class_map = {folder.name: idx for idx, folder in enumerate(sorted(data_dir.iterdir())) if folder.is_dir()}\n",
    "\n",
    "        for class_name, label in self.class_map.items():\n",
    "            csv_file = data_dir / class_name / \"data.csv\"\n",
    "            df = pd.read_csv(csv_file)\n",
    "            for _, row in df.iterrows():\n",
    "                self.data.append(row.values.astype(np.float32))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3074f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GestureDataset(root)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "790b6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'follow': 0, 'other': 1, 'stop': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e40e3",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "174416fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.LayerNorm(input_size),\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GestureModel(165, len(dataset.class_map))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "474f0346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1.0733340978622437\n",
      "Epoch: 2 Loss: 0.953346868356069\n",
      "Epoch: 3 Loss: 0.923482080300649\n",
      "Epoch: 4 Loss: 0.9169543186823527\n",
      "Epoch: 5 Loss: 0.8990113337834676\n",
      "Epoch: 6 Loss: 0.8676184813181559\n",
      "Epoch: 7 Loss: 0.8546401063601176\n",
      "Epoch: 8 Loss: 0.8258344729741415\n",
      "Epoch: 9 Loss: 0.8114627997080485\n",
      "Epoch: 10 Loss: 0.794398566087087\n",
      "Epoch: 11 Loss: 0.7760029037793478\n",
      "Epoch: 12 Loss: 0.7531235416730245\n",
      "Epoch: 13 Loss: 0.7383865118026733\n",
      "Epoch: 14 Loss: 0.7176188826560974\n",
      "Epoch: 15 Loss: 0.6968949238459269\n",
      "Epoch: 16 Loss: 0.6803903182347616\n",
      "Epoch: 17 Loss: 0.6609137455622355\n",
      "Epoch: 18 Loss: 0.6382696628570557\n",
      "Epoch: 19 Loss: 0.622866690158844\n",
      "Epoch: 20 Loss: 0.5932791928450266\n",
      "Epoch: 21 Loss: 0.5703293482462565\n",
      "Epoch: 22 Loss: 0.5479931632677714\n",
      "Epoch: 23 Loss: 0.5339322288831075\n",
      "Epoch: 24 Loss: 0.5010971029599508\n",
      "Epoch: 25 Loss: 0.4719899197419484\n",
      "Epoch: 26 Loss: 0.45643848180770874\n",
      "Epoch: 27 Loss: 0.4279033641020457\n",
      "Epoch: 28 Loss: 0.405046949783961\n",
      "Epoch: 29 Loss: 0.40074711044629413\n",
      "Epoch: 30 Loss: 0.3627396821975708\n",
      "Epoch: 31 Loss: 0.34474671880404156\n",
      "Epoch: 32 Loss: 0.3228530287742615\n",
      "Epoch: 33 Loss: 0.2995954751968384\n",
      "Epoch: 34 Loss: 0.29168063898881275\n",
      "Epoch: 35 Loss: 0.26397399107615155\n",
      "Epoch: 36 Loss: 0.2468762050072352\n",
      "Epoch: 37 Loss: 0.24161670605341592\n",
      "Epoch: 38 Loss: 0.2267086903254191\n",
      "Epoch: 39 Loss: 0.2225397676229477\n",
      "Epoch: 40 Loss: 0.1917605847120285\n",
      "Epoch: 41 Loss: 0.19196065763632456\n",
      "Epoch: 42 Loss: 0.17633922894795737\n",
      "Epoch: 43 Loss: 0.16996219754219055\n",
      "Epoch: 44 Loss: 0.1556283881266912\n",
      "Epoch: 45 Loss: 0.16678915669520697\n",
      "Epoch: 46 Loss: 0.19694753736257553\n",
      "Epoch: 47 Loss: 0.13800155371427536\n",
      "Epoch: 48 Loss: 0.1475700760881106\n",
      "Epoch: 49 Loss: 0.13827508687973022\n",
      "Epoch: 50 Loss: 0.11325158923864365\n",
      "Epoch: 51 Loss: 0.11734909812609355\n",
      "Epoch: 52 Loss: 0.10856484373410542\n",
      "Epoch: 53 Loss: 0.1016233464082082\n",
      "Epoch: 54 Loss: 0.09965416292349498\n",
      "Epoch: 55 Loss: 0.0968761717279752\n",
      "Epoch: 56 Loss: 0.0911533956726392\n",
      "Epoch: 57 Loss: 0.08860423664251964\n",
      "Epoch: 58 Loss: 0.09651718785365422\n",
      "Epoch: 59 Loss: 0.09199703236420949\n",
      "Epoch: 60 Loss: 0.08265597869952519\n",
      "Epoch: 61 Loss: 0.08086734513441722\n",
      "Epoch: 62 Loss: 0.07894688844680786\n",
      "Epoch: 63 Loss: 0.07620097448428471\n",
      "Epoch: 64 Loss: 0.0676180695494016\n",
      "Epoch: 65 Loss: 0.07147197425365448\n",
      "Epoch: 66 Loss: 0.06385796268781026\n",
      "Epoch: 67 Loss: 0.061789764712254204\n",
      "Epoch: 68 Loss: 0.06190402805805206\n",
      "Epoch: 69 Loss: 0.05628659762442112\n",
      "Epoch: 70 Loss: 0.055173698191841446\n",
      "Epoch: 71 Loss: 0.052790513883034386\n",
      "Epoch: 72 Loss: 0.05175299818317095\n",
      "Epoch: 73 Loss: 0.051240223149458565\n",
      "Epoch: 74 Loss: 0.04707557583848635\n",
      "Epoch: 75 Loss: 0.051073006043831505\n",
      "Epoch: 76 Loss: 0.047916002571582794\n",
      "Epoch: 77 Loss: 0.046877009173234306\n",
      "Epoch: 78 Loss: 0.04160895819465319\n",
      "Epoch: 79 Loss: 0.04337878276904424\n",
      "Epoch: 80 Loss: 0.03890460915863514\n",
      "Epoch: 81 Loss: 0.042565500984589257\n",
      "Epoch: 82 Loss: 0.03614374125997225\n",
      "Epoch: 83 Loss: 0.04057719558477402\n",
      "Epoch: 84 Loss: 0.03691872085134188\n",
      "Epoch: 85 Loss: 0.03340658297141393\n",
      "Epoch: 86 Loss: 0.034468381044765316\n",
      "Epoch: 87 Loss: 0.03541971929371357\n",
      "Epoch: 88 Loss: 0.037105398873488106\n",
      "Epoch: 89 Loss: 0.033517767364780106\n",
      "Epoch: 90 Loss: 0.03197315149009228\n",
      "Epoch: 91 Loss: 0.030069616933663685\n",
      "Epoch: 92 Loss: 0.028276247903704643\n",
      "Epoch: 93 Loss: 0.026360925287008286\n",
      "Epoch: 94 Loss: 0.03302035480737686\n",
      "Epoch: 95 Loss: 0.02874124050140381\n",
      "Epoch: 96 Loss: 0.025465153468151886\n",
      "Epoch: 97 Loss: 0.02686809500058492\n",
      "Epoch: 98 Loss: 0.026464808732271194\n",
      "Epoch: 99 Loss: 0.02246804938962062\n",
      "Epoch: 100 Loss: 0.02313322356591622\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.\n",
    "    for X, y in dataloader:\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch + 1} Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547226ff",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b9bd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1113 09:24:49.237000 3411882 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `GestureModel([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `GestureModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 17},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.0+cu128',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,165]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,3]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"model.0.weight\"<FLOAT,[165]>{TorchTensor(...)},\n",
       "                %\"model.0.bias\"<FLOAT,[165]>{TorchTensor(...)},\n",
       "                %\"model.1.bias\"<FLOAT,[128]>{TorchTensor(...)},\n",
       "                %\"model.3.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"model.5.weight\"<FLOAT,[3,64]>{TorchTensor(...)},\n",
       "                %\"model.5.bias\"<FLOAT,[3]>{TorchTensor<FLOAT,[3]>(Parameter containing: tensor([-0.0744, -0.0085, -0.0727], requires_grad=True), name='model.5.bias')},\n",
       "                %\"model.1.weight\"<FLOAT,[128,165]>{TorchTensor(...)},\n",
       "                %\"model.3.weight\"<FLOAT,[64,128]>{TorchTensor(...)}\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # node_layer_norm\n",
       "                 %\"layer_norm\"<FLOAT,[1,165]>, %\"\"<FLOAT,[1,1]>, %\"\"<FLOAT,[1,1]> ⬅️ ::LayerNormalization(%\"input\", %\"model.0.weight\"{...}, %\"model.0.bias\"{...}) {stash_type=1, epsilon=9.999999747378752e-06, axis=-1}\n",
       "            1 |  # node_linear\n",
       "                 %\"linear\"<FLOAT,[1,128]> ⬅️ ::Gemm(%\"layer_norm\", %\"model.1.weight\"{...}, %\"model.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            2 |  # node_relu\n",
       "                 %\"relu\"<FLOAT,[1,128]> ⬅️ ::Relu(%\"linear\")\n",
       "            3 |  # node_linear_1\n",
       "                 %\"linear_1\"<FLOAT,[1,64]> ⬅️ ::Gemm(%\"relu\", %\"model.3.weight\"{...}, %\"model.3.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            4 |  # node_relu_1\n",
       "                 %\"relu_1\"<FLOAT,[1,64]> ⬅️ ::Relu(%\"linear_1\")\n",
       "            5 |  # node_linear_2\n",
       "                 %\"output\"<FLOAT,[1,3]> ⬅️ ::Gemm(%\"relu_1\", %\"model.5.weight\"{...}, %\"model.5.bias\"{[-0.07441528886556625, -0.008452803827822208, -0.07268506288528442]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            return %\"output\"<FLOAT,[1,3]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_model_0_weight: \"f32[165]\", p_model_0_bias: \"f32[165]\", p_model_1_weight: \"f32[128, 165]\", p_model_1_bias: \"f32[128]\", p_model_3_weight: \"f32[64, 128]\", p_model_3_bias: \"f32[64]\", p_model_5_weight: \"f32[3, 64]\", p_model_5_bias: \"f32[3]\", x: \"f32[1, 165]\"):\n",
       "                     # File: /home/GTL/jmagana/.tb_follower_venv/lib/python3.12/site-packages/torch/nn/modules/normalization.py:229 in forward, code: return F.layer_norm(\n",
       "                    layer_norm: \"f32[1, 165]\" = torch.ops.aten.layer_norm.default(x, [165], p_model_0_weight, p_model_0_bias);  x = p_model_0_weight = p_model_0_bias = None\n",
       "            \n",
       "                     # File: /home/GTL/jmagana/.tb_follower_venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 128]\" = torch.ops.aten.linear.default(layer_norm, p_model_1_weight, p_model_1_bias);  layer_norm = p_model_1_weight = p_model_1_bias = None\n",
       "            \n",
       "                     # File: /home/GTL/jmagana/.tb_follower_venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[1, 128]\" = torch.ops.aten.relu.default(linear);  linear = None\n",
       "            \n",
       "                     # File: /home/GTL/jmagana/.tb_follower_venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1, 64]\" = torch.ops.aten.linear.default(relu, p_model_3_weight, p_model_3_bias);  relu = p_model_3_weight = p_model_3_bias = None\n",
       "            \n",
       "                     # File: /home/GTL/jmagana/.tb_follower_venv/lib/python3.12/site-packages/torch/nn/modules/activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[1, 64]\" = torch.ops.aten.relu.default(linear_1);  linear_1 = None\n",
       "            \n",
       "                     # File: /home/GTL/jmagana/.tb_follower_venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_2: \"f32[1, 3]\" = torch.ops.aten.linear.default(relu_1, p_model_5_weight, p_model_5_bias);  relu_1 = p_model_5_weight = p_model_5_bias = None\n",
       "                    return (linear_2,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_model_0_weight: PARAMETER target='model.0.weight'\n",
       "            p_model_0_bias: PARAMETER target='model.0.bias'\n",
       "            p_model_1_weight: PARAMETER target='model.1.weight'\n",
       "            p_model_1_bias: PARAMETER target='model.1.bias'\n",
       "            p_model_3_weight: PARAMETER target='model.3.weight'\n",
       "            p_model_3_bias: PARAMETER target='model.3.bias'\n",
       "            p_model_5_weight: PARAMETER target='model.5.weight'\n",
       "            p_model_5_bias: PARAMETER target='model.5.bias'\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear_2: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "dummy_input = torch.randn(1, 165)\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"gesture_mlp.onnx\",\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    opset_version=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b8076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tb_follower_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
